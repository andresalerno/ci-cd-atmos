# Pipeline de CD (Continuous Delivery)
# - Constrói e publica a imagem Docker do backend no Amazon ECR
# - Inicializa/planeja/aplica Terraform (stack mínima) para site estático em S3
# - Faz o build do frontend e publica no S3
# Disparos: push para main, tags semânticas (vX.Y.Z) e execução manual
name: CD Pipeline (Deploy)

on:
  # Permite disparo manual com flags de controle
  workflow_dispatch:
    inputs:
      apply:
        # Quando true, aplica o plano do Terraform durante execução manual
        description: "Apply Terraform and deploy (manual run)"
        type: boolean
        default: false
        required: false
      build_backend_image:
        # Quando true, força build & push da imagem do backend manualmente
        description: "Build & Push backend image (manual run)"
        type: boolean
        default: false
        required: false
  push:
    # Executa em pushes para a branch principal
    branches:
      - main
    # Também executa quando criadas tags no padrão vX.Y.Z
    tags:
      - 'v*.*.*'

permissions:
  # Permissões mínimas para ler conteúdos do repositório
  contents: read

jobs:
  deploy:
    # Runner padrão Ubuntu
    runs-on: ubuntu-latest
    # Usa o Environment "atmos" (segredos, aprovações, variáveis)
    environment: atmos
    env:
      # Variáveis de ambiente com fallback para valores padrão
      AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID || '058264220517' }}
      ECR_REPO_BACKEND: ${{ secrets.ECR_REPO_BACKEND || 'devops-study-backend' }}
      AWS_ROLE_ARN: ${{ secrets.AWS_ROLE_ARN }}

    outputs:
      site: ${{ steps.tfout.outputs.site }}
      bucket: ${{ steps.tfout.outputs.bucket }}
      image_tag: ${{ steps.build_push.outputs.image_tag }}

    steps:
      # Passo 1: Checkout do código-fonte
      - uses: actions/checkout@v4
        name: Checkout code

      # Passo 2: Verificação dos secrets (somente quando NÃO usar OIDC)
      - name: Check access key secrets
        if: ${{ env.AWS_ROLE_ARN == '' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          ECR_REPO_BACKEND: ${{ secrets.ECR_REPO_BACKEND }}
        run: |
          # Falha se credenciais obrigatórias não estiverem presentes
          missing=0
          if [ -z "${AWS_ACCESS_KEY_ID}" ]; then echo "::error::Missing secret AWS_ACCESS_KEY_ID"; missing=1; fi
          if [ -z "${AWS_SECRET_ACCESS_KEY}" ]; then echo "::error::Missing secret AWS_SECRET_ACCESS_KEY"; missing=1; fi
          # Para chaves long-lived, NÃO defina AWS_SESSION_TOKEN
          if [ -z "${AWS_SESSION_TOKEN}" ]; then echo "::notice::Missing AWS_SESSION_TOKEN (ok for long-lived keys)"; fi
          if [ -z "${AWS_REGION}" ]; then echo "::warning::Missing AWS_REGION; defaulting to us-east-1"; fi
          if [ -z "${AWS_ACCOUNT_ID}" ]; then echo "::warning::Missing AWS_ACCOUNT_ID (required for ECR build/push)"; fi
          if [ -z "${ECR_REPO_BACKEND}" ]; then echo "::warning::Missing ECR_REPO_BACKEND (required for ECR build/push)"; fi
          test "$missing" -eq 0

      # Passo 3A: Configura credenciais via OIDC (recomendado) quando houver AWS_ROLE_ARN
      - name: Configure AWS credentials (OIDC)
        if: ${{ env.AWS_ROLE_ARN != '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          role-session-name: gha-cd
          aws-region: ${{ env.AWS_REGION }}
          mask-aws-account-id: true

      # Passo 3B: Configura credenciais via chaves de acesso (fallback)
      - name: Configure AWS credentials (access keys)
        if: ${{ env.AWS_ROLE_ARN == '' }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.AWS_REGION }}
          mask-aws-account-id: true

      # Passo 3C: Verifica identidade AWS (debug de credenciais)
      - name: AWS caller identity
        run: |
          aws sts get-caller-identity

      # Passo 4: Realiza login no Amazon ECR (para push de imagens)
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # Passo 5: Garante que o repositório do ECR existe (idempotente)
      - name: Ensure ECR repository exists
        run: |
          # Cria o repositório se não existir
          aws ecr describe-repositories --repository-names "$ECR_REPO_BACKEND" >/dev/null 2>&1 \
            || aws ecr create-repository --repository-name "$ECR_REPO_BACKEND"

      # Passo 6: Build & Push do backend para o ECR
      - name: Build & Push Backend to ECR
        id: build_push
        run: |
          # Define repositório e tag (usa a tag de git quando existir, senão 'latest')
          IMAGE_REPO="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPO_BACKEND"
          IMAGE_TAG="${{ github.ref_type == 'tag' && github.ref_name || 'latest' }}"
          docker build -t "$IMAGE_REPO:latest" -t "$IMAGE_REPO:$IMAGE_TAG" ./backend
          docker push "$IMAGE_REPO:latest"
          docker push "$IMAGE_REPO:$IMAGE_TAG"
          echo "image_tag=$IMAGE_TAG" >> "$GITHUB_OUTPUT"

      # Passo 7: Setup do Terraform (stack mínima; sem criar novos roles IAM)
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init/Plan (minimal)
        working-directory: infra/terraform-min
        env:
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_IN_AUTOMATION: true
        run: |
          # Inicializa o backend/provider e gera o plano de execução
          terraform init -input=false
          terraform plan -input=false -out=tfplan

      # Passo 8: Aplica o plano do Terraform quando em tag, push na main ou execução manual com apply=true
      - name: Terraform Apply (minimal)
        if: startsWith(github.ref, 'refs/tags/v') || (github.event_name == 'workflow_dispatch' && inputs.apply == 'true') || (github.event_name == 'push' && github.ref == 'refs/heads/main')
        working-directory: infra/terraform-min
        env:
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_IN_AUTOMATION: true
        run: terraform apply -input=false -auto-approve tfplan

      # Passo 9: Lê outputs do Terraform (bucket e endpoint do site)
      - name: Read Terraform outputs (minimal)
        id: tfout
        working-directory: infra/terraform-min
        continue-on-error: true
        env:
          TF_IN_AUTOMATION: true
        run: |
          set -euo pipefail
          # Capture any Terraform chatter, then parse JSON using Python (no jq dependency)
          JSON_RAW="$(terraform -no-color output -json 2>&1 || true)"

          bucket="$(printf '%s\n' "$JSON_RAW" | python3 - <<'PY'
import json, sys
raw = sys.stdin.read()
start = raw.find('{')
obj = {}
if start != -1:
    try:
        obj = json.loads(raw[start:])
    except Exception:
        obj = {}
v = obj.get('s3_bucket_name', {})
print(v.get('value', '') if isinstance(v, dict) else '')
PY
)"

          site="$(printf '%s\n' "$JSON_RAW" | python3 - <<'PY'
import json, sys
raw = sys.stdin.read()
start = raw.find('{')
obj = {}
if start != -1:
    try:
        obj = json.loads(raw[start:])
    except Exception:
        obj = {}
v = obj.get('s3_website_endpoint', {})
print(v.get('value', '') if isinstance(v, dict) else '')
PY
)"

          {
            [ -n "$bucket" ] && echo "bucket=$bucket"
            [ -n "$site" ] && echo "site=$site"
          } >> "$GITHUB_OUTPUT"

      # Passo 10: Deploy ECS service (não aplicável)
      # Stack mínima: não há ECS neste pipeline

      # Passo 11: Setup do Node.js para build do frontend
      - name: Setup Node (frontend build)
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: 'npm'
          cache-dependency-path: frontend/package.json

      # Passo 12: Build do frontend
      - name: Build frontend
        working-directory: frontend
        run: |
          # Instalação resiliente: tenta npm ci; se lock estiver desatualizado, cai para npm i
          if [ -f package-lock.json ]; then npm ci || npm i --no-audit --no-fund; else npm i --no-audit --no-fund; fi
          npm run build

      # Passo 13: Publica artefatos do frontend no bucket S3 gerenciado pelo Terraform
      - name: Upload Frontend to S3
        run: |
          BUCKET="${{ steps.tfout.outputs.bucket }}"
          if [ -z "$BUCKET" ]; then
            echo "::notice::Skipping S3 upload: bucket output is empty (plan-only run or apply skipped)."
            exit 0
          fi
          aws s3 sync ./frontend/dist/ "s3://$BUCKET" --delete

      # Passo 14: Resumo do deploy com link do site estático
      - name: Deployment summary
        run: |
          SITE="${{ steps.tfout.outputs.site }}"
          if [ -n "$SITE" ]; then
            echo "Frontend (S3 website): http://$SITE" >> "$GITHUB_STEP_SUMMARY"
          fi

  cd-update-readme-meta:
    needs:
      - deploy
    if: ${{ always() && github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
          fetch-depth: 0
          persist-credentials: true
      - name: Update README CD meta and badge
        env:
          RUN_NUMBER: ${{ github.run_number }}
          ACTOR: ${{ github.actor }}
          SHA: ${{ github.sha }}
          REF_NAME: ${{ github.ref_name }}
          RESULT: ${{ needs.deploy.result }}
          SITE: ${{ needs.deploy.outputs.site }}
          BUCKET: ${{ needs.deploy.outputs.bucket }}
          IMAGE_TAG: ${{ needs.deploy.outputs.image_tag }}
        run: |
          set -euo pipefail
          DATE_UTC=$(date -u '+%Y-%m-%d %H:%M:%S')
          OVERALL="$RESULT"
          SITE_TXT=""; if [ -n "${SITE:-}" ]; then SITE_TXT=" • site: http://${SITE}"; fi
          TAG_TXT=""; if [ -n "${IMAGE_TAG:-}" ]; then TAG_TXT=" • tag: ${IMAGE_TAG}"; fi
          NEWLINE="Última execução do CD: ${DATE_UTC} UTC • ator: ${ACTOR} • branch: ${REF_NAME} • status: ${OVERALL}${TAG_TXT}${SITE_TXT} (run #${RUN_NUMBER})"
          awk -v repl="$NEWLINE" '
            BEGIN{inb=0}
            /<!-- cd-meta-start -->/{print; print repl; inb=1; next}
            /<!-- cd-meta-end -->/{inb=0}
            !inb{print}
          ' README.md > README.md.new

          mkdir -p .badges
          case "$OVERALL" in
            success) COLOR="brightgreen" ;;
            failure) COLOR="red" ;;
            cancelled) COLOR="yellow" ;;
            *) COLOR="lightgrey" ;;
          esac
          SHORT_TAG=""; if [ -n "${IMAGE_TAG:-}" ]; then SHORT_TAG=" • tag:${IMAGE_TAG}"; fi
          MESSAGE="${OVERALL} — ${DATE_UTC} UTC • ${ACTOR}${SHORT_TAG}"
          cat > .badges/cd-meta.json <<JSON
          {"schemaVersion":1,"label":"cd","message":"${MESSAGE}","color":"${COLOR}","cacheSeconds":60}
          JSON

          CHANGED=0
          if ! cmp -s README.md README.md.new; then
            mv README.md.new README.md
            CHANGED=1
          else
            rm -f README.md.new
          fi

          git config user.email "ci-bot@example.com"
          git config user.name "CI Setup Bot"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git pull --rebase || true
          git add .badges/cd-meta.json README.md || true
          if [ "$CHANGED" -eq 1 ] || ! git diff --cached --quiet; then
            git commit -m "docs: update CD meta and badge [skip ci]" || echo "Nothing to commit"
            git push
          else
            echo "No README or badge changes"
          fi
